CheML date="2016-01-21" time="16:30:29" version="1.2.0"

# Note: don't mix parameters and send&recv tokens in one line
# Note: don't make a short loop on only one function!
# Note: only one input per available legal input can be received
# Note: send: >> var id
# Note: recv: >> id var


## Enter Data
                << host = pandas                 << function = read_table

                < filepath_or_buffer = 'benchmarks/RI_project/liq_org/descriptors/dragon_1893.csv'
                < filepath_or_buffer = 'benchmarks/RI_project/liq_org/descriptors/HTT_bit.csv'
                << filepath_or_buffer = 'benchmarks/RI_project/liq_org/descriptors/Morgan_bit.csv'
                < filepath_or_buffer = 'benchmarks/RI_project/liq_org/descriptors/HAP_bit.csv'
                < filepath_or_buffer = 'benchmarks/RI_project/liq_org/descriptors/MACCS_bit.csv'
                << sep=','
                < header = 0
                << header = None
                << skiprows = 0
                >> df 0

## Prepare Data
                        << host = cheml         << function = Constant

                        >> 0 df
                        >> df 1


## Enter Data
                << host = pandas                 << function = read_table

                << filepath_or_buffer = 'benchmarks/RI_project/liq_org/pol_den_RI.csv'
                << sep=','
                << header = 0
                << skiprows = 0
                >> df 222

## Prepare Data
                << host = cheml                 << function = Split

                < selection = ['RI_LL']
                << selection = ['Pol_DFT']
                < selection = ['Den_MD']

                >> 222 df   >> df1 2



## Script
                        << host = cheml           << function = PyScript
                        << l0 = "print 'df:', df1.shape"
                        < l1 = "print df1.columns"
                        < l2 = "print df1.describe()"
                        << l3 = "print 'df2:', df2.shape"
                        << l4 = "print df2.describe()"
                        >> 1 df1    >> 2 df2


-------------------------- ML
## Scaler
                        << host = sklearn             << function = StandardScaler
                        << func_method = 'fit_transform'
                        << copy = True          << with_mean = True
                        << with_std = True

                        >> 1 df     >> df 11    > api 4

## Scaler
                        << host = sklearn             << function = StandardScaler
                        << func_method = 'fit_transform'
                        << copy = True          << with_mean = True
                        << with_std = True

                        >> 2 df     >> df 22    >> api 44


## Model
                        << host = sklearn        << function = MLPRegressor
                        << func_method = 'fit'

                        << hidden_layer_sizes = (128,64,32)
                        << activation = 'tanh'
                        < activation = 'logistic'
                        < activation = 'identity'
                        << alpha = 0.1

                        << solver = 'adam'
                        << batch_size = 'auto'
                        << learning_rate = 'invscaling'
                        << max_iter = 100000
                        << random_state = None
                        << shuffle = True
                        << tol = 1e-4
                        << learning_rate_init = 0.001
                        << power_t = 0.5
                        << early_stopping = True

                        >> 11 dfx  >> 22 dfy
                        >> api 101


## Model
                        << host = sklearn        << function = MLPRegressor
                        << func_method = 'predict'


                        >> 11 dfx    >> 101 api
                        >> dfy_pred 3

## Scaler
                        << host = sklearn             << function = StandardScaler
                        << func_method = 'inverse_transform'
                        << copy = True          << with_mean = True
                        << with_std = True

                        >> 3 df      >> 44 api
                        >> df 33

## Output
                << host = cheml                 << function = SaveFile

                << filename = 'y_all_pred'
                << output_directory = 'results'
                << record_time = False
                << format ='csv'
                << index = False
                << header = True
                >> 33 df

## Postprocessor
                << host = sklearn      << function = Evaluate_Regression
                              << r2_score = True
                              << r2_sample_weight = None       << r2_multioutput = None

                              << mean_absolute_error = True
                              << mae_sample_weight = None       << mae_multioutput = "uniform_average"

                              << median_absolute_error = True

                              << mean_squared_error = True
                              << mse_sample_weight = None       << mse_multioutput = "uniform_average"

                              << root_mean_squared_error = True
                              << rmse_sample_weight = None       << rmse_multioutput = "uniform_average"

                              << explained_variance_score = True
                              << ev_sample_weight = None       << ev_multioutput = "uniform_average"

                > Note: can not pass multiple inputs
                >> 2 dfy     >> 33 dfy_pred   >> evaluation_results_  1047


## Script
                        << host = cheml           << function = PyScript
                        << l0 = "print var1"

                        >> 1047 var1

## Output
                << host = cheml                 << function = SaveFile

                << filename = 'all_data_prediction_eval'
                << output_directory = 'results'
                << record_time = False
                << format ='csv'
                << index = True
                << header = True
                >> 1047 df



------------------------ learning curve
## Search
                        << host = sklearn               << function = ShuffleSplit
                        << n_splits = 10                << test_size = 0.1
                        << train_size = None            << random_state = 99
                        >> cv 100

## Metric
                << host = sklearn      << function = scorer_regression
                << metric = 'mae'
                << greater_is_better = False
                << needs_proba = False
                << needs_threshold = False
                << sample_weight = None
                << multioutput = 'raw_values'

                >> scorer 98

## Search
                << host = sklearn      << function = learning_curve

                              << estimator = '@estimator'
                              << train_sizes = [95, 428, 760, 1092, 1425, 1758, 2090, 2422, 2755, 3088, 3420, 3752, 4085, 4418, 4750, 5700, 12079, 18457, 24836, 31214, 37593, 43971, 50350, 56729, 63107, 69486, 75864, 82243, 88621, 90000]
                              < train_sizes = list(np.linspace(0.001, 0.05, 15)) + list(np.linspace(0.06, 1, 15))
                              << cv = '@cv'
                              << scoring = '@scorer'
                              << exploit_incremental_learning = False
                              << n_jobs = 7
                              << pre_dispatch = 'all'
                              << verbose = 0

                >> 11 dfx      >> 22 dfy   >> 101 estimator  >> 100 cv  >> 98 scorer
                >> train_scores 99  >> test_scores 102  >> extended_result_ 103


## Output
                << host = cheml                 << function = SaveFile

                << filename = 'extended_result'
                << output_directory = 'results'
                << record_time = False
                << format ='csv'
                << index = True
                << header = True
                >> 103 df

## Script
                        << host = cheml           << function = PyScript
                        << l0 = "print 'train_scores:', list(var1)"
                        << l1 = "print 'test_scores:', list(var2)"
                        >> 99 var1 >> 102 var2

# Output
                << host = cheml                 << function = StoreFile

                << filename = 'train_scores'
                << output_directory = 'results'
                << record_time = False
                << format ='txt'
                >> 99 input

# Output
                << host = cheml                 << function = StoreFile

                << filename = 'test_scores'
                << output_directory = 'results'
                << record_time = False
                << format ='txt'
                >> 102 input

---------------------------------