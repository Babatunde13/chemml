CheML date="2016-01-21" time="16:30:29" version="1.2.0"

# Note: don't mix parameters and send&recv tokens in one line
# Note: don't make a short loop on only one function!
# Note: only one input per available legal input can be received
# Note: send: >> var id
# Note: recv: >> id var


## Enter Data
                << host = pandas                 << function = read_table

                << filepath_or_buffer = 'benchmarks/RI_project/liq_org/results/learning_curve/mlp_k10_Morgan_ri/results/y_all_pred.csv'
                < filepath_or_buffer = 'benchmarks/RI_project/liq_org/results/learning_curve/mlp_k10_HAP_pol/results/y_all_pred.csv'
                < filepath_or_buffer = 'benchmarks/RI_project/liq_org/results/learning_curve/mlp_k10_HTT_d/results/y_all_pred.csv'
                << sep=','
                << header = 0
                << skiprows = 0
                >> df 51

## Enter Data
                << host = pandas                 << function = read_table

                << filepath_or_buffer = 'benchmarks/RI_project/liq_org/results/learning_curve/mlp_k10_HTT_ri/results/y_all_pred.csv'
                < filepath_or_buffer = 'benchmarks/RI_project/liq_org/results/learning_curve/mlp_k10_dragon_pol/results/y_all_pred.csv'
                < filepath_or_buffer = 'benchmarks/RI_project/liq_org/results/learning_curve/mlp_k10_dragon_d/results/y_all_pred.csv'
                << sep=','
                << header = 0
                << skiprows = 0
                >> df 52

## Enter Data
                << host = pandas                 << function = read_table

                << filepath_or_buffer = 'benchmarks/RI_project/liq_org/results/learning_curve/mlp_k10_dragon_ri/results/y_all_pred.csv'
                < filepath_or_buffer = 'benchmarks/RI_project/liq_org/results/learning_curve/mlp_k10_HTT_pol/results/y_all_pred.csv'
                < filepath_or_buffer = 'benchmarks/RI_project/liq_org/results/learning_curve/mlp_k10_HAP_d/results/y_all_pred.csv'
                << sep=','
                << header = 0
                << skiprows = 0
                >> df 53

## Input
                << host = cheml                 << function = Merge
                >> 51 df1   >> 52 df2   >> df 54

## Input
                << host = cheml                 << function = Merge
                >> 54 df1   >> 53 df2   >> df 1


## Enter Data
                << host = pandas                 << function = read_table

                << filepath_or_buffer = 'benchmarks/RI_project/liq_org/pol_den_RI.csv'
                << sep=','
                << header = 0
                << skiprows = 0
                >> df 222

## Prepare Data
                << host = cheml                 << function = Split
                << selection = ['RI_LL']
                < selection = ['Pol_DFT']
                < selection = ['Den_MD']
                >> 222 df   >> df1 2


## Script
                        << host = cheml           << function = PyScript
                        << l0 = "print 'df:', df1.shape"
                        < l1 = "print df1.columns"
                        < l2 = "print df1.describe()"
                        << l3 = "print 'df2:', df2.shape"
                        << l4 = "print df2.describe()"
                        >> 1 df1    >> 2 df2


-------------------------- ML
# Model
                        << host = sklearn        << function = MLPRegressor
                        << func_method = None
                        << hidden_layer_sizes = (100,50)
                        << activation = 'tanh'
                        << solver = 'adam'
                        < alpha = 0.0001
                        << batch_size = 'auto'
                        << learning_rate = 'invscaling'
                        << max_iter = 100000
                        << random_state = None
                        << shuffle = True
                        << tol = 1e-4
                        << learning_rate_init = 0.001
                        << power_t = 0.5
                        << early_stopping = True

                        >> api 101

## Model
                << host = sklearn      << function = SVR
                            << func_method = None
                              << C = 1.0
                              << epsilon = 0.1
                              << kernel = 'linear'
                              << degree = 3
                              << gamma = 'auto'
                              << coef0 = 0.0
                              << tol = 1e-3
                              << shrinking = True
                              << cache_size = 6000
                              << verbose = False
                              << max_iter = -1

                              >> api 101


## Scaler
                        << host = sklearn             << function = StandardScaler
                        << func_method = 'fit_transform'
                        << copy = True          << with_mean = True
                        << with_std = True

                        >> 1 df     >> df 11    > api 4

## Scaler
                        << host = sklearn             << function = StandardScaler
                        << func_method = 'fit_transform'
                        << copy = True          << with_mean = True
                        << with_std = True

                        >> 2 df     >> df 22    >> api 44

## Metric
                << host = sklearn      << function = scorer_regression
                << metric = 'mae'
                << greater_is_better = False
                << needs_proba = False
                << needs_threshold = False
                << sample_weight = None
                << multioutput = 'raw_values'

                >> scorer 98

## Search
                << host = sklearn      << function = GridSearchCV

                              << estimator = '@estimator'
                              << param_grid = {'C':(0.0001, 0.001, 0.01, 0.1,0.3),'epsilon':(0.0001, 0.001,0.01,0.03,0.1,0.3)}
                              < 'kernel':('linear','rbf','sigmoid'),

                              < param_grid = {'activation':('identity','logistic', 'tanh'),'hidden_layer_sizes':((128,64,32),(128,32,64),(32,64,128),(32,128,64),(64,32,128),(64,128,32)),'alpha':(1,0.7,0.3,0.1,0.01,0.001,0.0001,0.00001)}
                              < 'hidden_layer_sizes':((128,64,32),(128,32,64),(),(),(),()), ,'alpha':(0.01,0.001,0.0001)
                              <{'C':(0.01,0.1,1,10), 'epsilon':(0.01,0.1,1),'kernel':('linear','rbf','poly','sigmoid')}

                              << scoring = '@scorer'
                              << fit_params = None
                              << n_jobs = 8
                              << pre_dispatch = '2*n_jobs'
                              << iid = True
                              << cv = 2
                              << refit = True
                              << verbose = 0
                              << error_score = 'raise'
                              << return_train_score = True

                >> 11 dfx      >> 22 dfy   >> 101 estimator   >> 98 scorer
                >> best_estimator_ 102  >> cv_results_ 103


# Model
                        << host = sklearn        << function = MLPRegressor
                        << func_method = 'predict'


                        >> 11 dfx    >> 102 api
                        >> dfy_pred 3

## Model
                        << host = sklearn        << function = SVR
                        << func_method = 'predict'


                        >> 11 dfx    >> 102 api
                        >> dfy_pred 3

## Scaler
                        << host = sklearn             << function = StandardScaler
                        << func_method = 'inverse_transform'
                        << copy = True          << with_mean = True
                        << with_std = True

                        >> 3 df      >> 44 api
                        >> df 33


## Postprocessor
                << host = sklearn      << function = Evaluate_Regression
                              << r2_score = True
                              << r2_sample_weight = None       << r2_multioutput = None

                              << mean_absolute_error = True
                              << mae_sample_weight = None       << mae_multioutput = "uniform_average"

                              << median_absolute_error = True

                              << mean_squared_error = True
                              << mse_sample_weight = None       << mse_multioutput = "uniform_average"

                              << root_mean_squared_error = True
                              << rmse_sample_weight = None       << rmse_multioutput = "uniform_average"

                              << explained_variance_score = True
                              << ev_sample_weight = None       << ev_multioutput = "uniform_average"

                > Note: can not pass multiple inputs
                >> 2 dfy     >> 33 dfy_pred   >> evaluation_results_  1047


## Script
                        << host = cheml           << function = PyScript
                        << l0 = "print var1"

                        >> 1047 var1

## Output
                << host = cheml                 << function = SaveFile

                << filename = 'all_data_prediction_eval'
                << output_directory = 'results'
                << record_time = False
                << format ='csv'
                << index = True
                << header = True
                >> 1047 df

## Output
                << host = cheml                 << function = SaveFile

                << filename = 'cv_results'
                << output_directory = 'results'
                << record_time = False
                << format ='csv'
                << index = True
                << header = True
                >> 103 df



## Divider
                        << host = sklearn             << function = Train_Test_Split
                        << test_size = 0.01             << train_size = None
                        << random_state = None          << stratify = None
                        >> 11 dfx   >> 22 dfy     >> dfx_train 17  >> dfx_test 18  >> dfy_train 19  >> dfy_test 20

# Model
                        << host = sklearn        << function = MLPRegressor
                        << func_method = 'fit'

                        >> 17 dfx   >> 19 dfy >> 102 api
                        >> api 777

## Model
                        << host = sklearn        << function = SVR
                        << func_method = 'fit'

                        >> 17 dfx   >> 19 dfy >> 102 api
                        >> api 777

# Model
                        << host = sklearn        << function = MLPRegressor
                        << func_method = 'predict'

                        >> 18 dfx   >> 777 api
                        >> dfy_pred 21

## Model
                        << host = sklearn        << function = SVR
                       << func_method = 'predict'

                        >> 18 dfx   >> 777 api
                        >> dfy_pred 21


## Scaler
                        << host = sklearn             << function = StandardScaler
                        << func_method = 'inverse_transform'
                        << copy = True          << with_mean = True
                        << with_std = True

                        >> 21 df      >>  44 api
                        >> df 2121

## Scaler
                        << host = sklearn             << function = StandardScaler
                        << func_method = 'inverse_transform'
                        << copy = True          << with_mean = True
                        << with_std = True

                        >> 20 df      >>  44 api
                        >> df 2020

## Postprocessor
                << host = sklearn      << function = Evaluate_Regression
                              << r2_score = True
                              << r2_sample_weight = None       << r2_multioutput = None

                              << mean_absolute_error = True
                              << mae_sample_weight = None       << mae_multioutput = "uniform_average"

                              << median_absolute_error = True

                              << mean_squared_error = True
                              << mse_sample_weight = None       << mse_multioutput = "uniform_average"

                              << root_mean_squared_error = True
                              << rmse_sample_weight = None       << rmse_multioutput = "uniform_average"

                              << explained_variance_score = True
                              << ev_sample_weight = None       << ev_multioutput = "uniform_average"

                > Note: can not pass multiple inputs
                >> 2020 dfy     >> 2121 dfy_pred   >> evaluation_results_  227

## Output
                << host = cheml                 << function = SaveFile

                << filename = 'svr_results_split99:1'
                << output_directory = 'results'
                << record_time = False
                << format ='csv'
                << index = True
                << header = True
                >> 227 df

--------------------------------------------------------------------------
# Scaler
                        << host = sklearn             << function = StandardScaler
                        << func_method = 'fit_transform'
                        << copy = True          << with_mean = True
                        << with_std = True

                        >> 2 df     >> df 3    >> api 4

---------------------------------