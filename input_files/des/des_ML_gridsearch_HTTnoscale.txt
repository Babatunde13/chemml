CheML date="2016-01-21" time="16:30:29" version="1.2.0"

# Note: don't mix parameters and send&recv tokens in one line
# Note: don't make a short loop on only one function!
# Note: only one input per available legal input can be received
# Note: send: >> var id
# Note: recv: >> id var


## Enter Data
                << host = pandas                 << function = read_table

                < filepath_or_buffer = 'benchmarks/DES/MP/descriptors/clean_dragon.csv'
                << filepath_or_buffer = 'benchmarks/DES/MP/descriptors/HTT.csv'
                << sep=','
                < header = 0
                << header = None
                << skiprows = 0
                >> df 1


## Enter Data
                << host = pandas                 << function = read_table

                < filepath_or_buffer = 'benchmarks/DES/MP/descriptors/clean_dragon_mp.csv'
                << filepath_or_buffer = 'benchmarks/DES/MP/descriptors/HTT_mp.csv'
                << sep=','
                << header = 0
                << skiprows = 0
                >> df 2


## Script
                        << host = cheml           << function = PyScript
                        << l0 = "print 'df:', df1.shape"
                        < l1 = "print df1.columns"
                        < l2 = "print df1.describe()"
                        << l3 = "print 'df2:', df2.shape"
                        << l4 = "print df2.describe()"
                        >> 1 df1    >> 2 df2

# Preprocessor
                        << host = cheml             << function = MissingValues
                        << string_as_null = True    << missing_values = ['Nan']
                        << inf_as_null = True       << strategy = 'ignore_column'
                        >> 1 dfx >> 2 dfy  >> dfx 3  >> dfy 4

# Script
                        << host = cheml           << function = PyScript
                        << l0 = "print 'dfx:', df1.shape"
                        << l1 = "print 'dfy:', df2.shape"
                        < l2 = "print df1.describe()"
                        >> 3 df1 >> 4 df2


-------------------------- ML
# Model
                        << host = sklearn        << function = MLPRegressor
                        << func_method = None
                        < hidden_layer_sizes = (128,64,32)
                        < activation = 'tanh'
                        << solver = 'adam'
                        < alpha = 0.0001
                        << batch_size = 'auto'
                        << learning_rate = 'invscaling'
                        << max_iter = 100000
                        << random_state = None
                        << shuffle = True
                        << tol = 1e-4
                        << learning_rate_init = 0.001
                        << power_t = 0.5
                        << early_stopping = True

                        >> api 101

## Model
                << host = sklearn      << function = SVR
                            << func_method = None
                              << C = 1.0
                              << epsilon = 0.1
                              << kernel = 'rbf'
                              << degree = 3
                              << gamma = 'auto'
                              << coef0 = 0.0
                              << tol = 1e-3
                              << shrinking = True
                              << cache_size = 6000
                              << verbose = False
                              << max_iter = -1

                              >> api 101

## Scaler
                        << host = sklearn             << function = StandardScaler
                        << func_method = 'fit_transform'
                        << copy = True          << with_mean = True
                        << with_std = True

                        >> 1 df     >> df 11    > api 4

## Scaler
                        << host = sklearn             << function = StandardScaler
                        << func_method = 'fit_transform'
                        << copy = True          << with_mean = True
                        << with_std = True

                        >> 2 df     >> df 22    >> api 44



## Search
                << host = sklearn      << function = GridSearchCV

                              << estimator = '@estimator'
                              << param_grid = {'kernel':('linear','rbf','sigmoid'),'C':(0.0001, 0.001,0.005,0.01),'epsilon':(0.0001, 0.001,0.01)}

                              <{'C':(0.01,0.1,1,10), 'epsilon':(0.01,0.1,1),'kernel':('linear','rbf','poly','sigmoid')}
                              << scoring = None
                              << fit_params = None
                              << n_jobs = 16
                              << pre_dispatch = '2*n_jobs'
                              << iid = True
                              << cv = None
                              << refit = True
                              << verbose = 0
                              << error_score = 'raise'
                              << return_train_score = True

                >> 11 dfx      >> 22 dfy   >> 101 estimator
                >> best_estimator_ 102  >> cv_results_ 103


## Model
                        << host = sklearn        << function = SVR
                        << func_method = 'predict'


                        >> 11 dfx    >> 102 api
                        >> dfy_pred 3

## Scaler
                        << host = sklearn             << function = StandardScaler
                        << func_method = 'inverse_transform'
                        << copy = True          << with_mean = True
                        << with_std = True

                        >> 3 df      >> 44 api
                        >> df 33


## Postprocessor
                << host = sklearn      << function = Evaluate_Regression
                              << r2_score = True
                              << r2_sample_weight = None       << r2_multioutput = None

                              << mean_absolute_error = True
                              << mae_sample_weight = None       << mae_multioutput = "uniform_average"

                              << median_absolute_error = True

                              << mean_squared_error = True
                              << mse_sample_weight = None       << mse_multioutput = "uniform_average"

                              << root_mean_squared_error = True
                              << rmse_sample_weight = None       << rmse_multioutput = "uniform_average"

                              << explained_variance_score = True
                              << ev_sample_weight = None       << ev_multioutput = "uniform_average"

                > Note: can not pass multiple inputs
                >> 2 dfy     >> 33 dfy_pred   >> evaluation_results_  1047


## Script
                        << host = cheml           << function = PyScript
                        << l0 = "print var1"

                        >> 1047 var1

## Output
                << host = cheml                 << function = SaveFile

                << filename = 'all_data_prediction_eval'
                << output_directory = 'results'
                << record_time = False
                << format ='csv'
                << index = True
                << header = True
                >> 1047 df

## Output
                << host = cheml                 << function = SaveFile

                << filename = 'cv_results'
                << output_directory = 'results'
                << record_time = False
                << format ='csv'
                << index = True
                << header = True
                >> 103 df



## Divider
                        << host = sklearn             << function = Train_Test_Split
                        << test_size = 0.1             << train_size = None
                        << random_state = None          << stratify = None
                        >> 11 dfx   >> 22 dfy     >> dfx_train 17  >> dfx_test 18  >> dfy_train 19  >> dfy_test 20

## Model
                        << host = sklearn        << function = SVR
                        << func_method = 'fit'

                        >> 17 dfx   >> 19 dfy >> 102 api
                        >> api 777

## Model
                        << host = sklearn        << function = SVR
                        << func_method = 'predict'


                        >> 18 dfx   >> 777 api
                        >> dfy_pred 21

## Scaler
                        << host = sklearn             << function = StandardScaler
                        << func_method = 'inverse_transform'
                        << copy = True          << with_mean = True
                        << with_std = True

                        >> 21 df      >>  44 api
                        >> df 2121

## Scaler
                        << host = sklearn             << function = StandardScaler
                        << func_method = 'inverse_transform'
                        << copy = True          << with_mean = True
                        << with_std = True

                        >> 20 df      >>  44 api
                        >> df 2020

## Postprocessor
                << host = sklearn      << function = Evaluate_Regression
                              << r2_score = True
                              << r2_sample_weight = None       << r2_multioutput = None

                              << mean_absolute_error = True
                              << mae_sample_weight = None       << mae_multioutput = "uniform_average"

                              << median_absolute_error = True

                              << mean_squared_error = True
                              << mse_sample_weight = None       << mse_multioutput = "uniform_average"

                              << root_mean_squared_error = True
                              << rmse_sample_weight = None       << rmse_multioutput = "uniform_average"

                              << explained_variance_score = True
                              << ev_sample_weight = None       << ev_multioutput = "uniform_average"

                > Note: can not pass multiple inputs
                >> 2020 dfy     >> 2121 dfy_pred   >> evaluation_results_  227

## Output
                << host = cheml                 << function = SaveFile

                << filename = 'svr_results_split9:1'
                << output_directory = 'results'
                << record_time = False
                << format ='csv'
                << index = True
                << header = True
                >> 227 df

--------------------------------------------------------------------------
# Scaler
                        << host = sklearn             << function = StandardScaler
                        << func_method = 'fit_transform'
                        << copy = True          << with_mean = True
                        << with_std = True

                        >> 2 df     >> df 3    >> api 4

---------------------------------